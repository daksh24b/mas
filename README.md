# VeriFlow: Multimodal Digital Trust & Forensic Memory Agent

## ğŸ¯ Executive Summary

VeriFlow is an innovative AI-powered system that addresses the critical challenge of cross-platform misinformation by creating a "forensic memory" that tracks and verifies claims across different media types over time. Unlike traditional fact-checking tools that focus on a single medium, VeriFlow uses Qdrant's multimodal vector database to find semantic links between text, images, and audio content.

## ğŸŒŸ Key Features

### 1. **Multimodal Search**
- Store embeddings of images, audio transcripts, and text in a single Qdrant collection
- Query an image and find related text-based claims
- Cross-platform tracking of misinformation evolution

### 2. **Temporal Memory**
- Track how claims evolve and transform across platforms
- Update trust scores as new evidence emerges
- Maintain historical progression of claim credibility

### 3. **Traceable Reasoning**
- Provide complete evidence trails: "This claim first appeared in Image A, then morphed into Audio Clip B, and was debunked by Report C"
- Explainable AI with reasoning chains
- Transparent trust score calculations

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     FastAPI Backend                         â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚   Claims     â”‚  â”‚   Search     â”‚  â”‚  Provenance  â”‚    â”‚
â”‚  â”‚   Endpoint   â”‚  â”‚   Endpoint   â”‚  â”‚   Reports    â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                â”‚                â”‚
             â–¼                â–¼                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Core Services Layer                        â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Embedding Serviceâ”‚  â”‚  Trust Service   â”‚               â”‚
â”‚  â”‚  - CLIP (Image)  â”‚  â”‚  - Score Calc    â”‚               â”‚
â”‚  â”‚  - Whisper (Audioâ”‚  â”‚  - Memory Mgmt   â”‚               â”‚
â”‚  â”‚  - Transformers  â”‚  â”‚  - Evolution     â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚ Qdrant Service   â”‚  â”‚ Search Service   â”‚               â”‚
â”‚  â”‚  - Vector Ops    â”‚  â”‚  - Hybrid Search â”‚               â”‚
â”‚  â”‚  - Metadata      â”‚  â”‚  - Reasoning     â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Qdrant Vector DB                         â”‚
â”‚                                                             â”‚
â”‚  Collection: veriflow_claims                               â”‚
â”‚  - 512D CLIP embeddings                                    â”‚
â”‚  - Rich metadata (trust scores, timestamps, platforms)     â”‚
â”‚  - Indexed fields for hybrid search                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Technical Implementation

### Vector Storage Schema

```python
Vector: 512-dimensional CLIP embedding
Payload: {
    "claim_id": str,
    "media_type": "text" | "image" | "audio" | "video",
    "platform": "twitter" | "facebook" | "youtube" | ...,
    "trust_score": float (0-1),
    "trust_level": "verified" | "likely_true" | "uncertain" | "likely_false" | "debunked",
    "timestamp": datetime,
    "last_updated": datetime,
    "verification_count": int,
    "supporting_evidence_count": int,
    "refuting_evidence_count": int,
    "original_text": str,
    "transcription": str (for audio),
    "tags": list[str]
}
```

### Hybrid Search Strategy

VeriFlow combines three search dimensions:

1. **Semantic Search**: CLIP embeddings enable cross-modal similarity
2. **Metadata Filtering**: Platform, trust level, timestamp filters
3. **Trust Score Ranking**: Prioritize verified content

### Trust Score Algorithm

```python
Trust Score = f(
    source_credibility,      # 0-1
    platform_reliability,    # 0-1
    supporting_evidence,     # count and quality
    refuting_evidence,       # count and quality
    time_decay,             # older claims decay toward neutral
    verification_sources     # official fact-checkers boost
)
```

## ğŸ“Š Use Cases

### 1. **Fact-Checkers**
Query a suspicious image â†’ Find all related text claims â†’ See debunking evidence

### 2. **Journalists**
Track how a false narrative evolved from Twitter to TikTok to mainstream media

### 3. **Researchers**
Analyze misinformation patterns across platforms and media types

### 4. **Platform Moderators**
Identify coordinated misinformation campaigns spanning multiple formats

## ğŸš€ Getting Started

### Prerequisites

- Python 3.9+
- Qdrant (Docker or Cloud)
- 8GB+ RAM (for local ML models)
- GPU recommended (for faster embeddings)

### Installation

```bash
# Clone repository
git clone <repository-url>
cd mas

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Copy environment template
cp .env.example .env

# Edit .env with your configuration
nano .env
```

### Start Qdrant

```bash
# Option 1: Docker
docker run -p 6333:6333 qdrant/qdrant

# Option 2: Cloud
# Use Qdrant Cloud URL and API key in .env
```

### Initialize Database

```bash
# Generate sample data
python -m src.data_ingestion --type sample --count 100

# Or load WELFake dataset
python -m src.data_ingestion --type welfake --path path/to/welfake.csv --limit 1000
```

### Start API Server

```bash
# Development mode with auto-reload
uvicorn src.main:app --reload --host 0.0.0.0 --port 8000

# Production mode
uvicorn src.main:app --host 0.0.0.0 --port 8000 --workers 4
```

### Run Demo

```bash
python demo.py
```

## ğŸ“– API Documentation

Once running, visit:
- **Interactive Docs**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc
- **Health Check**: http://localhost:8000/health

### Key Endpoints

#### Submit Text Claim
```bash
curl -X POST "http://localhost:8000/claims/text" \
  -H "Content-Type: application/json" \
  -d '{
    "text": "Your claim text here",
    "platform": "twitter",
    "source_url": "https://twitter.com/...",
    "tags": ["covid19", "health"]
  }'
```

#### Submit Image Claim
```bash
curl -X POST "http://localhost:8000/claims/image" \
  -F "image=@path/to/image.jpg" \
  -F "platform=instagram" \
  -F "caption=Optional caption"
```

#### Search Claims
```bash
curl -X POST "http://localhost:8000/search" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "vaccine misinformation",
    "media_type": "text",
    "min_trust_score": 0.5,
    "limit": 10
  }'
```

#### Get Provenance Report
```bash
curl -X GET "http://localhost:8000/claims/{claim_id}/provenance"
```

## ğŸ“ How It Maximizes Qdrant's Capabilities

### 1. **Multimodal Vectors**
- Single collection stores text, image, and audio embeddings
- CLIP's shared embedding space enables cross-modal search
- Query with text, find related images (and vice versa)

### 2. **Payload-Based Memory**
```python
# Initial state
trust_score: 0.5, verification_count: 0

# After evidence added
trust_score: 0.85, verification_count: 5

# Qdrant's set_payload enables temporal tracking
```

### 3. **Hybrid Search**
```python
# Semantic + Metadata filtering in single query
results = qdrant.search(
    collection_name="veriflow_claims",
    query_vector=embedding,
    query_filter=Filter(
        must=[
            FieldCondition(key="trust_level", match="verified"),
            FieldCondition(key="platform", match="twitter")
        ]
    )
)
```

### 4. **Efficient Indexing**
- Indexed payload fields: `media_type`, `platform`, `trust_level`, `trust_score`, `timestamp`
- Fast filtered searches on billions of vectors
- Real-time updates without reindexing

## ğŸ“ˆ Performance Characteristics

- **Embedding Generation**: ~100ms per text, ~300ms per image, ~2s per audio (base Whisper)
- **Vector Search**: <50ms for top-10 results (1M vectors)
- **Provenance Report**: ~200ms (includes related claims search)
- **Throughput**: ~100 requests/sec (single worker)

## ğŸ”’ Privacy & Ethics

- **No Personal Data**: System tracks claims, not individuals
- **Source Attribution**: Always preserve original source URLs
- **Transparency**: All trust scores are explainable
- **Open Methodology**: Algorithm is auditable

## ğŸ› ï¸ Development

### Project Structure
```
mas/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI application
â”‚   â”œâ”€â”€ config.py               # Configuration
â”‚   â”œâ”€â”€ models.py               # Pydantic models
â”‚   â”œâ”€â”€ qdrant_service.py       # Qdrant operations
â”‚   â”œâ”€â”€ embedding_service.py    # CLIP, Whisper, embeddings
â”‚   â”œâ”€â”€ trust_service.py        # Trust scoring logic
â”‚   â”œâ”€â”€ search_service.py       # Hybrid search
â”‚   â””â”€â”€ data_ingestion.py       # Dataset loading
â”œâ”€â”€ demo.py                     # Interactive demo
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

### Adding New Media Types

1. Add to `MediaType` enum in [models.py](models.py)
2. Implement embedding method in [embedding_service.py](embedding_service.py)
3. Add API endpoint in [main.py](main.py)
4. Update provenance report generation

### Custom Trust Algorithms

Extend `TrustScoreCalculator` in [trust_service.py](trust_service.py):

```python
def calculate_custom_score(self, claim, evidence):
    # Your custom logic
    return score
```

## ğŸ§ª Testing

```bash
# Unit tests
pytest tests/

# Load test
locust -f tests/load_test.py

# End-to-end test
python demo.py
```

## ğŸ“Š Example Queries

### Cross-Modal Search
```python
# Upload image, find related text claims
POST /claims/image
â†’ Returns claim_id

GET /claims/{claim_id}?related=true
â†’ Returns semantically similar claims across all media types
```

### Temporal Evolution
```python
# Track how claim evolved over time
GET /claims/{claim_id}/provenance
â†’ Returns timeline showing:
  - First appearance (image on Instagram)
  - Morphed version (audio on podcast)
  - Debunking (text article)
```

### Trust Decay
```python
# Claims without updates decay toward neutral
Initial: trust_score = 0.9 (verified)
After 180 days: trust_score = 0.7 (needs re-verification)
```

## ğŸŒ Deployment

### Docker Deployment
```bash
# Build image
docker build -t veriflow:latest .

# Run container
docker run -p 8000:8000 \
  -e QDRANT_HOST=qdrant \
  -e OPENAI_API_KEY=your_key \
  veriflow:latest
```

### Cloud Deployment (AWS/GCP/Azure)
- Use managed Qdrant Cloud
- Deploy FastAPI with container service
- Add CDN for static assets
- Enable auto-scaling based on load

## ğŸ”® Future Enhancements

1. **Video Support**: Frame-by-frame analysis + audio track
2. **Real-time Monitoring**: WebSocket API for live claim tracking
3. **Graph Visualization**: Interactive evolution graphs
4. **LLM Integration**: GPT-4 for nuanced claim analysis
5. **Blockchain Verification**: Immutable evidence records

## ğŸ“š References

- [Qdrant Documentation](https://qdrant.tech/documentation/)
- [CLIP Paper](https://arxiv.org/abs/2103.00020)
- [Whisper Paper](https://arxiv.org/abs/2212.04356)
- [WELFake Dataset](https://www.kaggle.com/datasets/saurabhshahane/fake-news-classification)

## ğŸ“„ License

MIT License - See LICENSE file for details

## ğŸ‘¥ Authors

VeriFlow Team - Convolve 4.0 Hackathon

## ğŸ™ Acknowledgments

- Qdrant team for the amazing vector database
- OpenAI for CLIP and Whisper models
- The fact-checking community for inspiration

---

**Built with â¤ï¸ for a more truthful internet**
